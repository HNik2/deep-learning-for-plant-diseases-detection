# -*- coding: utf-8 -*-
"""model2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tbdN_QFIHB07IcavRfRLa9quIgdTpach
"""

#importation des bibliothèque nécessaires

from __future__ import absolute_import, division, print_function, unicode_literals

!pip install tf-nightly-gpu-2.0-preview
import tensorflow as tf
import os
import numpy as np
import matplotlib.pyplot as plt
import IPython.display as display
from PIL import Image
import os
import zipfile
import pathlib
AUTOTUNE = tf.data.experimental.AUTOTUNE

tf.__version__

#Chargement de mon drive dans l'environnement de travail de Google colaboratory

from google.colab import drive
drive.mount('/content/drive')

# Copie du jeu de données des maladies des plantes dans google colaboratory
cp /content/drive/My\ Drive/dataset.zip /

#Décompression du jeu de données
local_zip = '/dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/')
zip_ref.close()

#Définition des répertoires pour les données d'entrainement et les données de validation
train_dir = '/dataset/train/'
valid_dir = '/dataset/valid/'
train_dir = pathlib.Path(train_dir)
valid_dir = pathlib.Path(valid_dir)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
import datetime

#Pour compter le nombre d'images du répertoire d'entrainement
image_count = len(list(train_dir.glob('*/*.JPG')))
image_count

#POur récupérer les différentes classes du jeu de données
CLASS_NAMES = np.array([item.name for item in train_dir.glob('*') if item.name != "LICENSE.txt"])
CLASS_NAMES

#Affichage des feuilles de tomates en bonne santé
tomates = list(train_dir.glob('Tomato___healthy/*'))

for image_path in tomates[:3]:
    display.display(Image.open(str(image_path)))

#prétaitement des images du jeu de données pour l'adapter à l'entrée de notre modèle
BATCH_SIZE = 32
IMG_HEIGHT = 299
IMG_WIDTH = 299
STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)


# The 1./255 is to convert from uint8 to float32 in range [0,1].
image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_data_gen = image_generator.flow_from_directory(directory=str(train_dir),
                                                     batch_size=BATCH_SIZE,
                                                     shuffle=True,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     classes = list(CLASS_NAMES))

test_data_gen = image_generator.flow_from_directory(directory=str(valid_dir),
                                                     batch_size=BATCH_SIZE,
                                                     shuffle=True,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     classes = list(CLASS_NAMES))

#Affichage des shape des images après le prétraitement
for image_batch, label_batch in train_data_gen:
  break
image_batch.shape, label_batch.shape

#Construction du fichier label pour contenir les différentes classes du jeu de données
print (train_data_gen.class_indices)

labels = '\n'.join(sorted(train_data_gen.class_indices.keys()))

with open('labels.txt', 'w') as f:
  f.write(labels)

#Affichage du fichier label
!cat labels.txt

#Fonction d'affichage de quelques images 
def show_batch(image_batch, label_batch):
  plt.figure(figsize=(50,50))
  for n in range(25):
      ax = plt.subplot(5,5,n+1)
      plt.imshow(image_batch[n])
      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())
      #plt.axis('off')

#affichage de quelques images 

image_batch, label_batch = next(train_data_gen)
show_batch(image_batch, label_batch)

#chargement du modèle pré-entrainé inception V3
IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)

base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, weights='imagenet', include_top=False)

#rendre les couche du modèle pré-entrainé, non entrainable

base_model.trainable = False
#afficher un aperçu du modèle
base_model.summary()

#ajout du modèle pré-entrainé et d'autres couches supplémentaires à notre propre modèle 
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(2048, activation='relu')(x)
x = tf.keras.layers.Dense(1024, activation='relu')(x)
predictions = tf.keras.layers.Dense(38, activation='softmax')(x)

# this is the model we will train
model = tf.keras.Model(inputs=base_model.input, outputs=predictions)

#Compiler le modèle
model.compile(loss="categorical_crossentropy", optimizer=tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9), metrics=["accuracy"])
model.summary()

#lancer l'entreinement du modèle
history_fine = model.fit(train_data_gen, 
                         epochs=10,
                         validation_data=test_data_gen)